{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc071d2d",
   "metadata": {},
   "source": [
    "# Tutorial 04: Run the Training and Test Phases of the WGAST Model\n",
    "\n",
    "In this tutorial, we will run the **WGAST** model on the structured dataset we prepared earlier. This includes:\n",
    "\n",
    "- Setting up all necessary parameters and model configurations.\n",
    "- Launching the training process.\n",
    "- Evaluating the trained model.\n",
    "\n",
    "📌 This tutorial is fully customizable. The default parameters match the settings used in our paper, feel free to adjust them based on your data or hardware capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a656bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the project root to sys.path to allow imports from other folders (e.g., 'runner', 'data_loader', etc.)\n",
    "sys.path.append(os.path.abspath('..'))  # Assumes this notebook is in /tutorials/\n",
    "\n",
    "from runner.experiment import Experiment  # Main class to manage training and testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c387a4",
   "metadata": {},
   "source": [
    "## Step 01 : Define and Initialize Model Parameters (from the Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481adb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialization\n",
      "There are 7884208 trainable parameters for generator.\n",
      "There are 2765505 trainable parameters for nlayerdiscriminator.\n"
     ]
    }
   ],
   "source": [
    "# === Configuration Class ===\n",
    "class Options:\n",
    "    \"\"\"\n",
    "    Stores all hyperparameters and paths used during training/testing.\n",
    "\n",
    "    ⚠️ NOTE: The folder './data/Tdivision' must be generated by the previous tutorials:\n",
    "        - 01_data_download.ipynb\n",
    "        - 02_data_preparation.ipynb\n",
    "        - 03_data_structuring.ipynb\n",
    "\n",
    "    📌 These hyperparameters correspond to the settings used in the paper.\n",
    "       Feel free to adjust them for your own experiments.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Training settings\n",
    "        self.lr = 2e-4                  # Learning rate\n",
    "        self.batch_size = 32           # Batch size\n",
    "        self.epochs = 110              # Number of training epochs\n",
    "\n",
    "        # Hardware settings\n",
    "        self.cuda = True               # Enable CUDA if available\n",
    "        self.ngpu = 1                  # Number of GPUs to use\n",
    "        self.num_workers = 8           # Number of data loading workers\n",
    "\n",
    "        # Data paths\n",
    "        self.save_dir = Path('./data/Tdivision')      # Where to save outputs\n",
    "        self.data_dir = Path('./data/Tdivision')      # Base data directory\n",
    "        self.train_dir = Path('./data/Tdivision/train')  # Training data path\n",
    "        self.test_dir = Path('./data/Tdivision/test')    # Testing data path\n",
    "\n",
    "        # Image and patch parameters\n",
    "        self.image_size = [400, 400]   # Size of input images\n",
    "        self.patch_size = [32, 32]     # Size of image patches\n",
    "        self.patch_stride = 8          # Stride for patch extraction\n",
    "        self.test_patch = 32           # Patch size during testing\n",
    "\n",
    "        # Model options\n",
    "        self.ifAdaIN = True            # Use AdaIN for feature normalization\n",
    "        self.ifAttention = True        # Use attention mechanism\n",
    "        self.ifTwoInput = False        # Use two input streams (if applicable)\n",
    "        \n",
    "        # Loss weights (used in final objective function)\n",
    "        self.a = 1e-2\n",
    "        self.b = 1\n",
    "        self.c = 1\n",
    "        self.d = 1\n",
    "\n",
    "# === Set Options ===\n",
    "opt = Options()\n",
    "\n",
    "# === Set random seed for reproducibility ===\n",
    "torch.manual_seed(2024)\n",
    "opt.cuda = True  # Enable CUDA if available\n",
    "if not torch.cuda.is_available():\n",
    "    opt.cuda = False\n",
    "\n",
    "if opt.cuda:\n",
    "    torch.cuda.manual_seed_all(2024)\n",
    "    cudnn.benchmark = True       # Enable benchmark mode for optimal performance\n",
    "    cudnn.deterministic = True   # Make training deterministic (reproducible)\n",
    "\n",
    "# === Run Experiment ===\n",
    "# This initializes the training/testing workflow\n",
    "experiment = Experiment(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea1cc3",
   "metadata": {},
   "source": [
    "## Step 02 : Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd87e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.epochs > 0:\n",
    "    start_time = time.time()  # Start measuring training time\n",
    "    \n",
    "    # Begin training process using parameters defined earlier\n",
    "    # - opt.train_dir: Path to the training dataset (prepared in previous tutorials)\n",
    "    # - patch_size / patch_stride: How images are split into training patches\n",
    "    # - batch_size: Number of samples per training batch\n",
    "    # - num_workers: Number of subprocesses used for data loading\n",
    "    # - epochs: Number of full passes over the dataset\n",
    "    predictions = experiment.train(opt.train_dir,\n",
    "                                   opt.patch_size, \n",
    "                                   opt.patch_stride, \n",
    "                                   opt.batch_size,\n",
    "                                   num_workers=1, \n",
    "                                   epochs=opt.epochs)\n",
    "\n",
    "    end_time = time.time()  # Stop measuring training time\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Training took {elapsed_time:.2f} seconds\")  # Display training duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472dc8c2",
   "metadata": {},
   "source": [
    "## Step 03 : Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7423e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model using the test dataset\n",
    "# - opt.test_dir: Path to the test dataset (should be pre-generated in earlier steps)\n",
    "# - patch_size: Size of the patches used for testing\n",
    "# - num_workers: Number of parallel data loading workers\n",
    "\n",
    "results = experiment.test(opt.test_dir,\n",
    "                          opt.patch_size,\n",
    "                          num_workers=1)\n",
    "\n",
    "# Print or log the results as needed\n",
    "print(\"Testing completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
